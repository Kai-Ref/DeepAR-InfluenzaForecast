for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
print(rowname)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
#print(quantiles)
#region_row <- c(rowname, quantiles)
#region_df <- rbind(region_df, region_row)
#region_df[, ] <- c(rowname, quantiles, region)
region_df <- rbind(region_df, c(rowname, quantiles, region))
}
}
# Add location name to the regional data frame
#region_df$Location <- region
print(region_df)
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
print(combined_df)
#print(region_df)
#location_list[[region]] <- region_df
}
for (region in regions[1:3]){
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 7, dimnames = list(NULL, c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
print(rowname)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
#print(quantiles)
#region_row <- c(rowname, quantiles)
#region_df <- rbind(region_df, region_row)
region_df[rowname, ] <- quantiles#c(rowname, quantiles, region)
#region_df <- rbind(region_df, c(rowname, quantiles, region))
}
}
# Add location name to the regional data frame
#region_df$Location <- region
print(region_df)
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
print(combined_df)
#print(region_df)
#location_list[[region]] <- region_df
}
combined_df <- data.frame()
for (region in regions[1:3]){
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 7, dimnames = list(NULL, c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
print(rowname)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
#print(quantiles)
#region_row <- c(rowname, quantiles)
#region_df <- rbind(region_df, region_row)
region_df[rowname, ] <- quantiles#c(rowname, quantiles, region)
#region_df <- rbind(region_df, c(rowname, quantiles, region))
}
}
# Add location name to the regional data frame
#region_df$Location <- region
print(region_df)
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
print(combined_df)
#print(region_df)
#location_list[[region]] <- region_df
}
combined_df <- data.frame()
combined_df <- data.frame()
for (region in regions[1:3]){
i<-0
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
print(rowname)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
#print(quantiles)
#region_row <- c(rowname, quantiles)
#region_df <- rbind(region_df, region_row)
region_df[i, ] <- c(rowname, quantiles, region)
#region_df <- rbind(region_df, c(rowname, quantiles, region))
i<-i+1
}
}
# Add location name to the regional data frame
#region_df$Location <- region
print(region_df)
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
print(combined_df)
#print(region_df)
#location_list[[region]] <- region_df
}
for (region in regions[1:3]){
i<-1
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
print(rowname)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
#print(quantiles)
#region_row <- c(rowname, quantiles)
#region_df <- rbind(region_df, region_row)
region_df[i, ] <- c(rowname, quantiles, region)
#region_df <- rbind(region_df, c(rowname, quantiles, region))
i<-i+1
}
}
# Add location name to the regional data frame
#region_df$Location <- region
print(region_df)
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
print(combined_df)
#print(region_df)
#location_list[[region]] <- region_df
}
combined_df <- data.frame()
for (region in regions[1:3]){
i<-1
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
print(rowname)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
#print(quantiles)
#region_row <- c(rowname, quantiles)
#region_df <- rbind(region_df, region_row)
region_df[i, ] <- c(rowname, quantiles, region)
#region_df <- rbind(region_df, c(rowname, quantiles, region))
i<-i+1
}
}
# Add location name to the regional data frame
#region_df$Location <- region
print(region_df)
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
print(combined_df)
#print(region_df)
#location_list[[region]] <- region_df
}
combined_df <- data.frame()
i<-1
for (region in regions[1:3]){
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
region_df[i, ] <- c(rowname, quantiles, region)
i<-i+1
}
}
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
}
print(combined_df)
combined_df <- data.frame()
for (region in regions[1:3]){
i<-1
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
region_df[i, ] <- c(rowname, quantiles, region)
i<-i+1
}
}
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
}
print(combined_df)
regions <- unique(data$location)
location_list <- list()
combined_df <- data.frame()
for (region in regions){
i<-1
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results[1:3]){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
region_df[i, ] <- c(rowname, quantiles, region)
i<-i+1
}
}
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
}
print(combined_df)
regions <- unique(data$location)
location_list <- list()
combined_df <- data.frame()
for (region in regions){
i<-1
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
region_df[i, ] <- c(rowname, quantiles, region)
i<-i+1
}
}
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
}
print(combined_df)
write.csv(combined_df, file = "C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast/R/results.csv", row.names = FALSE)
print(df)
print(df[train_length:train_length+2])
print(df[,train_length:train_length+2])
print(df[train_length:train_length+2,])
print(df[train_length:train_length+1,])
print(df[train_length:train_length,])
print(df[train_length:train_length,"LK Ahrweiler"])
print(df[train_length:train_length+4,"LK Ahrweiler"])
print(df[train_length:(train_length+4),"LK Ahrweiler"])
print(df[train_length:(train_length+4),"LK Karlsruhe"])
print(df[train_length:(train_length+4),"SK München"])
print(df[train_length:(train_length+4),["SK München", "date"])
print(df[train_length:(train_length+4),"SK München", "date")
print(df[train_length:(train_length+4),"SK München":"date")
print(df[train_length:(train_length+4),["SK München","date"]])
print(df[train_length:(train_length+4),c("SK München","date")])
print(df[test_length-4:(test_length+4),c("SK München","date")])
print(df[(test_length-4):(test_length+4),c("SK München","date")])
print(df[(train_length):(test_length+4),c("SK München","date")])
library(tidyr)
library(surveillance)
setwd("C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast")
data <- read.csv("Notebooks/DataProcessing/influenza.csv")
adjacentMatrix <- read.csv("Notebooks/DataProcessing/AdjacentMatrix.csv", check.names=FALSE,
row.names='')
population_vector <- read.csv("Notebooks/DataProcessing/PopulationVector.csv",
check.names=FALSE, row.names = "Location")
df <- pivot_wider(data[c('value', 'date', 'location')], names_from = location, values_from = value)
print(df[1:4,"date"])
# Filter the DataFrame for dates before '30.09.2016'
train_length <- length(unique(df[df$date < as.Date("2018-09-30"), ]$date))
test_length <- length(unique(df[df$date < as.Date("2020-09-30"), ]$date))
print(df[(train_length):(test_length+4),c("SK München","date")])
df[is.na(df)] <- 0
df_sts <-sts(as.matrix(subset(df, select=-c(date))),
start = c(2001, 1) , frequency = 52,# maybe take len(df)/years here or 52.25
neighbourhood = as.matrix(adjacentMatrix),
population = as.vector(t(population_vector)))
?addSeason2formula
plot(df_sts[1:train_length], type = observed ~ time)
f.ne <- addSeason2formula(~-1 + ri(type="iid", corr="all") + log(pop), S = 1, period = 52)
f.end <- addSeason2formula(~-1 + ri(type="iid", corr="all") + I((t-208)/100), S = 1, period = 52)
nbOrder1 <- neighbourhood(df_sts)
neighbourhood(df_sts) <- nbOrder(nbOrder1, 15) + 1
## full model specification
fluModel <- list(ar = list(f = ~ -1),
ne = list(f = f.ne,weights = W_powerlaw(maxlag=max(neighbourhood(df_sts)),
normalize = TRUE, log = TRUE)),
end = list(f = f.end, offset = population(df_sts)),
family = "NegBin1",
data = list(pop = population(df_sts)),
optimizer = list(variance = list(method = "Nelder-Mead")),
verbose = TRUE,
subset = 1:train_length)
set.seed(1)
fluFit <- hhh4(df_sts, fluModel)
library(hhh4addon)
vignette("hhh4")
vignette("hhh4_spacetime")
results <- list()
for (t_condition in (train_length):(test_length)){
path_forecast <- predictive_moments(fluFit, t_condition = t_condition, lgt = 4)
results[[t_condition - train_length + 1]] <- path_forecast
print(t_condition)
}
regions <- unique(data$location)
combined_df <- data.frame()
for (region in regions){
i<-1
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
region_df[i, ] <- c(rowname, quantiles, region)
i<-i+1
}
}
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
}
print(combined_df)
write.csv(combined_df, file = "C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast/R/validation_results.csv", row.names = FALSE)
print(df[(train_length):(test_length+4),c("SK München","date")])
print(df[(train_length):(test_length+4),:])
print(df[(train_length):(test_length+4),])
print(df[(train_length):(test_length+4),c("SK München","date")])
print(df[(train_length-4):train_length,c("SK München","date")])
print(len(df[:train_length,c("SK München","date")]))
print(len(df[1:train_length,c("SK München","date")]))
print(dim(df[1:train_length,c("SK München","date")]))
print(df[(train_length-4):train_length+1,c("SK München","date")])
print(df[(train_length):(test_length+4),c("SK München","date")])
plot(df_sts[1:train_length], type = observed ~ time)
print(df[(test_length-4):test_length+1,c("SK München","date")])
print(df[(train_length-4):train_length+4,c("SK München","date")])
print(df[(test_length-4):test_length+4,c("SK München","date")])
print(df[(train_length-4):train_length+4,c("SK München","date")])
print(df[(test_length-4):test_length+4,c("SK München","date")])
print(df[(test_length-4):(test_length+4),c("SK München","date")])
print(df[929,c("SK München","date")])
print(df[1025,c("SK München","date")])
print(dim(df[1:train_length,c("SK München","date")]))
print(dim(df[1:train_length,c("SK München","date")]))
print(dim(df[0:train_length,c("SK München","date")]))
print(df[train_length,c("SK München","date")])
# Filter the DataFrame for dates before '30.09.2016'
train_length <- length(unique(df[df$date <= as.Date("2018-09-30"), ]$date))
test_length <- length(unique(df[df$date <= as.Date("2020-09-30"), ]$date))
print(dim(df[0:train_length,c("SK München","date")]))
print(df[train_length,c("SK München","date")])
library(tidyr)
library(surveillance)
setwd("C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast")
data <- read.csv("Notebooks/DataProcessing/influenza.csv")
adjacentMatrix <- read.csv("Notebooks/DataProcessing/AdjacentMatrix.csv", check.names=FALSE,
row.names='')
population_vector <- read.csv("Notebooks/DataProcessing/PopulationVector.csv",
check.names=FALSE, row.names = "Location")
df <- pivot_wider(data[c('value', 'date', 'location')], names_from = location, values_from = value)
print(df[1:4,"date"])
# Filter the DataFrame for dates before '30.09.2016'
train_length <- length(unique(df[df$date <= as.Date("2018-09-30"), ]$date))
test_length <- length(unique(df[df$date <= as.Date("2020-09-30"), ]$date))
print(df[(train_length+1):(test_length+4),c("SK München","date")])
print(df[(train_length-4):train_length+4,c("SK München","date")])
print(df[(test_length-4):(test_length+4),c("SK München","date")])
print(dim(df[0:train_length,c("SK München","date")]))
print(df[train_length,c("SK München","date")])
df[is.na(df)] <- 0
df_sts <-sts(as.matrix(subset(df, select=-c(date))),
start = c(2001, 1) , frequency = 52,# maybe take len(df)/years here or 52.25
neighbourhood = as.matrix(adjacentMatrix),
population = as.vector(t(population_vector)))
?addSeason2formula
plot(df_sts[1:train_length], type = observed ~ time)
plot(df_sts, unit = 16)
f.ne <- addSeason2formula(~-1 + ri(type="iid", corr="all") + log(pop), S = 1, period = 52)
f.end <- addSeason2formula(~-1 + ri(type="iid", corr="all") + I((t-208)/100), S = 1, period = 52)
nbOrder1 <- neighbourhood(df_sts)
neighbourhood(df_sts) <- nbOrder(nbOrder1, 15) + 1
## full model specification
fluModel <- list(ar = list(f = ~ -1),
ne = list(f = f.ne,weights = W_powerlaw(maxlag=max(neighbourhood(df_sts)),
normalize = TRUE, log = TRUE)),
end = list(f = f.end, offset = population(df_sts)),
family = "NegBin1",
data = list(pop = population(df_sts)),
optimizer = list(variance = list(method = "Nelder-Mead")),
verbose = TRUE,
subset = 1:train_length)
set.seed(1)
fluFit <- hhh4(df_sts, fluModel)
# 3. hhh4addon
# ability to add higher order lags
# computation of predictive and marginal first and second moments
# to get forecasts at longer horizons without the need to simulate you can use the hhh4addon package:
library(hhh4addon)
vignette("hhh4")
vignette("hhh4_spacetime")
results <- list()
for (t_condition in (train_length):(test_length)){
path_forecast <- predictive_moments(fluFit, t_condition = t_condition, lgt = 4)
results[[t_condition - train_length + 1]] <- path_forecast
print(t_condition)
}
regions <- unique(data$location)
combined_df <- data.frame()
for (region in regions){
i<-1
print(region)
region_df <- data.frame(matrix(nrow = 0, ncol = 9, dimnames = list(NULL, c("Time",0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975, "Location"))), stringsAsFactors = FALSE)
colnames(region_df) <- sub("^X", "", colnames(region_df))
for (path_forecast in results){
# determine the distribution parameters for each region and path_forecast
mu <- path_forecast$mu_matrix[, region]
sigma2 <- path_forecast$var_matrix[, region]
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
# determine quantiles from the distribution parameters
for (t in 1:4){
time_point <-as.numeric(sub("^t=", "", names(mu[t])))
rowname <- sprintf("%s.%s",  time_point,t)
quantiles <- qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu[t], size = size[t])
region_df[i, ] <- c(rowname, quantiles, region)
i<-i+1
}
}
# Concatenate the regional data frame with the combined data frame
combined_df <- rbind(combined_df, region_df)
}
print(combined_df)
write.csv(combined_df, file = "C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast/R/validation_results.csv", row.names = FALSE)
print(df[train_length,c("SK München","date")])
print(df[927,c("SK München","date")])
print(df[1034,c("SK München","date")])
print(df[1030,c("SK München","date")])
print(df[930,c("SK München","date")])
print(df[1027,c("SK München","date")])
citation(package="surveillance")
