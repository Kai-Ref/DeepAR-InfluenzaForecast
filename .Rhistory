install.packages("surveillance")
data <- read.csv("C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast/Influenza.csv")
influenza <-disProg2sts(data)
library(surveillance)
data <- read.csv("C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast/Influenza.csv")
influenza <-disProg2sts(data)
plot(influenza)
## convert old "disProg" to new "sts" data class
salmonella <- disProg2sts(salmonella.agona)
data("salmonella.agona")
## convert old "disProg" to new "sts" data class
salmonella <- disProg2sts(salmonella.agona)
plot(salmonella)
## Example hhh4
data("salmonella.agona")
## convert old "disProg" to new "sts" data class
salmonella <- disProg2sts(salmonella.agona)
plot(salmonella)
## generate formula for an (endemic) time trend and seasonality
f.end <- addSeason2formula(f = ~1 + t, S = 1, period = 52)
f.end
## specify a simple autoregressive negative binomial model
model1 <- list(ar = list(f = ~1), end = list(f = f.end), family = "NegBin1")
## fit this model to the data
res <- hhh4(salmonella, model1)
## summarize the model fit
summary(res, idx2Exp=1, amplitudeShift=TRUE, maxEV=TRUE)
plot(res)
plot(res, type = "season", components = "end")
### weekly counts of meningococcal infections, Germany, 2001-2006
data("influMen")
fluMen <- disProg2sts(influMen)
meningo <- fluMen[, "meningococcus"]
meningo
plot(meningo)
## again a simple autoregressive NegBin model with endemic seasonality
meningoFit <- hhh4(stsObj = meningo, control = list(
ar = list(f = ~1),
end = list(f = addSeason2formula(f = ~1, S = 1, period = 52)),
family = "NegBin1"
))
summary(meningoFit, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)
plot(meningoFit)
plot(meningoFit, type = "season", components = "end")
########################
## Multivariate examples
########################
### bivariate analysis of influenza and meningococcal infections
### (see Paul et al, 2008)
plot(fluMen, same.scale = FALSE)
## Fit a negative binomial model with
## - autoregressive component: disease-specific intercepts
## - neighbour-driven component: only transmission from flu to men
## - endemic component: S=3 and S=1 sine/cosine pairs for flu and men, respectively
## - disease-specific overdispersion
WfluMen <- neighbourhood(fluMen)
WfluMen["meningococcus","influenza"] <- 0
WfluMen
f.end_fluMen <- addSeason2formula(f = ~ -1 + fe(1, which = c(TRUE, TRUE)),
S = c(3, 1), period = 52)
f.end_fluMen
fluMenFit <- hhh4(fluMen, control = list(
ar = list(f = ~ -1 + fe(1, unitSpecific = TRUE)),
ne = list(f = ~ 1, weights = WfluMen),
end = list(f = f.end_fluMen),
family = "NegBinM"))
summary(fluMenFit, idx2Exp=1:3)
plot(fluMenFit, type = "season", components = "end", unit = 1)
plot(fluMenFit, type = "season", components = "end", unit = 2)
# \dontshow{
## regression test for amplitude/shift transformation of sine-cosine pairs
## coefficients were wrongly matched in surveillance < 1.18.0
stopifnot(coef(fluMenFit, amplitudeShift = TRUE)["end.A(2 * pi * t/52).meningococcus"] == sqrt(sum(coef(fluMenFit)[paste0("end.", c("sin","cos"), "(2 * pi * t/52).meningococcus")]^2)))
### weekly counts of measles, Weser-Ems region of Lower Saxony, Germany
data("measlesWeserEms")
measlesWeserEms
plot(measlesWeserEms)  # note the two districts with zero cases
## we could fit the same simple model as for the salmonella cases above
model1 <- list(
ar = list(f = ~1),
end = list(f = addSeason2formula(~1 + t, period = 52)),
family = "NegBin1"
)
measlesFit <- hhh4(measlesWeserEms, model1)
summary(measlesFit, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)
## but we should probably at least use a population offset in the endemic
## component to reflect heterogeneous incidence levels of the districts,
## and account for spatial dependence (here just using first-order adjacency)
measlesFit2 <- update(measlesFit,
end = list(offset = population(measlesWeserEms)),
ne = list(f = ~1, weights = neighbourhood(measlesWeserEms) == 1))
summary(measlesFit2, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)
plot(measlesFit2, units = NULL, hide0s = TRUE)
## 'measlesFit2' corresponds to the 'measlesFit_basic' model in
## vignette("hhh4_spacetime"). See there for further analyses,
## including vaccination coverage as a covariate,
## spatial power-law weights, and random intercepts.
if (FALSE) {
### last but not least, a more sophisticated (and time-consuming)
### analysis of weekly counts of influenza from 140 districts in
### Southern Germany (originally analysed by Paul and Held, 2011,
### and revisited by Held and Paul, 2012, and Meyer and Held, 2014)
data("fluBYBW")
plot(fluBYBW, type = observed ~ time)
plot(fluBYBW, type = observed ~ unit,
## mean yearly incidence per 100.000 inhabitants (8 years)
population = fluBYBW@map$X31_12_01 / 100000 * 8)
## For the full set of models for data("fluBYBW") as analysed by
## Paul and Held (2011), including predictive model assessement
## using proper scoring rules, see the (computer-intensive)
## demo("fluBYBW") script:
demoscript <- system.file(file.path("demo", "fluBYBW.R"),
package = "surveillance")
demoscript
#file.show(demoscript)
## Here we fit the improved power-law model of Meyer and Held (2014)
## - autoregressive component: random intercepts + S = 1 sine/cosine pair
## - neighbour-driven component: random intercepts + S = 1 sine/cosine pair
##   + population gravity with normalized power-law weights
## - endemic component: random intercepts + trend + S = 3 sine/cosine pairs
## - random intercepts are iid but correlated between components
f.S1 <- addSeason2formula(
~-1 + ri(type="iid", corr="all"),
S = 1, period = 52)
f.end.S3 <- addSeason2formula(
~-1 + ri(type="iid", corr="all") + I((t-208)/100),
S = 3, period = 52)
## for power-law weights, we need adjaceny orders, which can be
## computed from the binary adjacency indicator matrix
nbOrder1 <- neighbourhood(fluBYBW)
neighbourhood(fluBYBW) <- nbOrder(nbOrder1, 15)
## full model specification
fluModel <- list(
ar = list(f = f.S1),
ne = list(f = update.formula(f.S1, ~ . + log(pop)),
weights = W_powerlaw(maxlag=max(neighbourhood(fluBYBW)),
normalize = TRUE, log = TRUE)),
end = list(f = f.end.S3, offset = population(fluBYBW)),
family = "NegBin1", data = list(pop = population(fluBYBW)),
optimizer = list(variance = list(method = "Nelder-Mead")),
verbose = TRUE)
## CAVE: random effects considerably increase the runtime of model estimation
## (It is usually advantageous to first fit a model with simple intercepts
## to obtain reasonable start values for the other parameters.)
set.seed(1)  # because random intercepts are initialized randomly
fluFit <- hhh4(fluBYBW, fluModel)
summary(fluFit, idx2Exp = TRUE, amplitudeShift = TRUE)
plot(fluFit, type = "fitted", total = TRUE)
plot(fluFit, type = "season")
range(plot(fluFit, type = "maxEV"))
plot(fluFit, type = "maps", prop = TRUE)
gridExtra::grid.arrange(
grobs = lapply(c("ar", "ne", "end"), function (comp)
plot(fluFit, type = "ri", component = comp, main = comp,
exp = TRUE, sub = "multiplicative effect")),
nrow = 1, ncol = 3)
plot(fluFit, type = "neweights", xlab = "adjacency order")
}
########################################################################
## An endemic-only "hhh4" model can also be estimated using MASS::glm.nb
########################################################################
## weekly counts of measles, Weser-Ems region of Lower Saxony, Germany
data("measlesWeserEms")
## fit an endemic-only "hhh4" model
## with time covariates and a district-specific offset
hhh4fit <- hhh4(measlesWeserEms, control = list(
end = list(f = addSeason2formula(~1 + t, period = measlesWeserEms@freq),
offset = population(measlesWeserEms)),
ar = list(f = ~-1), ne = list(f = ~-1), family = "NegBin1",
subset = 1:nrow(measlesWeserEms)
))
summary(hhh4fit)
## fit the same model using MASS::glm.nb
measlesWeserEmsData <- as.data.frame(measlesWeserEms, tidy = TRUE)
measlesWeserEmsData$t <- c(hhh4fit$control$data$t)
glmnbfit <- MASS::glm.nb(
update(formula(hhh4fit)$end, observed ~ . + offset(log(population))),
data = measlesWeserEmsData
)
summary(glmnbfit)
## Note that the overdispersion parameter is parametrized inversely.
## The likelihood and point estimates are all the same.
## However, the variance estimates are different: in glm.nb, the parameters
## are estimated conditional on the overdispersion theta.
# \dontshow{
stopifnot(
all.equal(logLik(hhh4fit), logLik(glmnbfit)),
all.equal(1/coef(hhh4fit)[["overdisp"]], glmnbfit$theta, tolerance = 1e-6),
all.equal(coef(hhh4fit)[1:4], coef(glmnbfit),
tolerance = 1e-6, check.attributes = FALSE),
all.equal(c(residuals(hhh4fit)), residuals(glmnbfit),
tolerance = 1e-6, check.attributes = FALSE)
)
?hhh4
library(tidyr)
library(surveillance)
?hhh4
library(tidyr)
library(surveillance)
# Data for all states
setwd("C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast")
data <- read.csv("Notebooks/DataProcessing/influenza.csv")
adjacentMatrix <- read.csv("Notebooks/DataProcessing/AdjacentMatrix.csv", check.names=FALSE,
row.names='')
population_vector <- read.csv("Notebooks/DataProcessing/PopulationVector.csv",
check.names=FALSE, row.names = "Location")
# For Developing purpose select only the BW data (faster computations)
# data <- read.csv("Notebooks/DataProcessing/BWDataset/influenzaBW.csv")
# adjacentMatrix <- read.csv("Notebooks/DataProcessing/BWDataset/AdjacentMatrixBW.csv",
#                           check.names=FALSE,row.names='Index')
# population_vector <- read.csv("Notebooks/DataProcessing/BWDataset/PopulationVectorBW.csv",
#                              check.names=FALSE, row.names = "Location")
df <- pivot_wider(data[c('value', 'date', 'location')], names_from = location, values_from = value)
df[is.na(df)] <- 0
df_sts <-sts(as.matrix(subset(df, select=-c(date))),
start = c(2002, 1) , frequency = 52.25,# maybe take len(df)/years here
neighbourhood = as.matrix(adjacentMatrix),
population = as.vector(t(population_vector)))
plot(df_sts, type = observed ~ time)
?hhh4
?sts
## Here we fit the improved power-law model of Meyer and Held (2014)
## - autoregressive component: random intercepts + S = 1 sine/cosine pair
## - neighbour-driven component: random intercepts + S = 1 sine/cosine pair
##   + population gravity with normalized power-law weights
## - endemic component: random intercepts + trend + S = 3 sine/cosine pairs
## - random intercepts are iid but correlated between components
f.ne <- addSeason2formula(
~-1 + ri(type="iid", corr="all") + log(pop), # spatially correlated random effects
## JB: added population offset here directly for better readability
S = 1, period = 52) # seasonality with one pair of sine-cosine waves
f.end <- addSeason2formula(
~-1 + ri(type="iid", corr="all") + I((t-208)/100), # spatially correlated random effects and a linear time trend
S = 1, period = 52) # seasonality with three sine cosine waves
## JB: I set S = 1 here as I don't think there is much of a point in adding 3 waves here
## (the EN component plays hardly any role anyway)
## for power-law weights, we need adjaceny orders, which can be
## computed from the binary adjacency indicator matrix
nbOrder1 <- neighbourhood(df_sts)
neighbourhood(df_sts) <- nbOrder(nbOrder1, 15) + 1
## JB: I added plus one here so we can subsume the AR in the NE component
## i.e., we treat the same region now as if it was a direct neighbour, the direct neighbours
## as if they were second-order neighbours etc. This removes quite a few parameters and in my
## opinion is a more reasonable model anyway as otherwise we have separate terms for seasonality
## in the two components, which does not make sense.
plot(df_sts, unit = 9)
## full model specification
fluModel <- list(
ar = list(f = ~ -1), ## JB: I removed the AR component here as it is now subsumed in the NE component, see above
ne = list(f = f.ne, # adding a population offset; this means large regions attract more infections
weights = W_powerlaw(maxlag=max(neighbourhood(df_sts)),
normalize = TRUE, log = TRUE)),
end = list(f = f.end, offset = population(df_sts)), # population offset in the intercept; number of "unexplained" cases depends on population size
family = "NegBin1", data = list(pop = population(df_sts)),
optimizer = list(variance = list(method = "Nelder-Mead")),
verbose = TRUE,
subset = 2:364) # important for prediction: fit only to first seven years
#print(population(fluBYBW))
print(population(df_sts))
## CAVE: random effects considerably increase the runtime of model estimation
## (It is usually advantageous to first fit a model with simple intercepts
## to obtain reasonable start values for the other parameters.)
set.seed(1)  # because random intercepts are initialized randomly
fluFit <- hhh4(df_sts, fluModel)
summary(fluFit, idx2Exp = TRUE, amplitudeShift = TRUE)
plot(fluFit, type = "fitted", total = TRUE)
plot(fluFit, type = "season")
range(plot(fluFit, type = "maxEV"))
plot(fluFit, type = "maps", prop = TRUE)
gridExtra::grid.arrange(
grobs = lapply(c("ar", "ne", "end"), function (comp)
plot(fluFit, type = "ri", component = comp, main = comp,
exp = TRUE, sub = "multiplicative effect")),
nrow = 1, ncol = 3)
plot(fluFit, type = "neweights", xlab = "adjacency order")
osa <- oneStepAhead(fluFit, tp = c(364, 415), # tp is shifted by one, see documentation
type = "final") # "final" means the model is not updated after each week.
plot(osa, start = 2009, unit  =2)
plot(osa, start = 2009, unit  =2)
plot(osa, start = 2000, unit  =2)
library(hhh4addon)
path_forecast <- predictive_moments(fluFit, t_condition = 364, lgt = 5)
fanplot_prediction(path_forecast)
plot(fluFit, type = "fitted", unit = 16)# unit equals the LKs
fanplot_prediction(path_forecast, unit = 16, add  =TRUE)
mu <- path_forecast$mu_matrix
sigma2 <- path_forecast$var_matrix
size <- pmin(abs(mu / (sigma2 / mu - 1)), 10000)
plot(dnbinom(0:20, mu = mu[1, 1], size = size[1, 1]))
qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu["t=1", "1"], size = size["t=1", "1"])
qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu["t=369", "LK Bad Dürkheim"], size = size["t=369", "LK Bad Dürkheim"])
qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu["t=368", "LK Bad Dürkheim"], size = size["t=368", "LK Bad Dürkheim"])
qnbinom(p = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
mu = mu["t=369", "LK Bad Dürkheim"], size = size["t=369", "LK Bad Dürkheim"])
save.image("C:/Users/555ka/Coding/GIT-Projects/DeepAR_InfluenzaForecast/DeepAR_InfluenzaForecast/R/workspace.RData")
View(sigma2)
View(mu)
View(size)
?hhh4addon
