{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c900f869-5c04-458b-8c3d-8ae03e89083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/reffert/DeepAR_InfluenzaForecast')\n",
    "from PythonFiles.model import model, preprocessing, split_forecasts_by_week, plot_coverage, print_forecasts_by_week, forecast_by_week, train_test_split, update_deepAR_parameters\n",
    "from PythonFiles.Configuration import Configuration\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.rolling_dataset import generate_rolling_dataset,StepStrategy\n",
    "config = Configuration()\n",
    "influenza_df = pd.read_csv(\"/home/reffert/DeepAR_InfluenzaForecast/Notebooks/DataProcessing/influenza.csv\", sep=',')\n",
    "population_df = pd.read_csv(\"/home/reffert/DeepAR_InfluenzaForecast/Notebooks/DataProcessing/PopulationVector.csv\", sep=',')\n",
    "neighbourhood_df = pd.read_csv(\"/home/reffert/DeepAR_InfluenzaForecast/Notebooks/DataProcessing/AdjacentMatrix.csv\", sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbc4fb2-c18f-4318-957c-6f0f17bdfd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_start_time = datetime(1999,1,1,0,0,0)#datetime(2010,1,1,0,0,0)\n",
    "config.train_end_time = datetime(2016,9,30,23,0,0)\n",
    "config.test_end_time = datetime(2018,9,30,23,0,0)\n",
    "overall_evaluation_df = pd.DataFrame()\n",
    "\n",
    "data_splits_dict = {}\n",
    "output_dict = {}\n",
    "\n",
    "locations = list(influenza_df.location.unique())\n",
    "#Process the df into a uniformly spaced df\n",
    "df = influenza_df.loc[influenza_df.location.isin(locations), ['value', 'location', 'date','week']]\n",
    "df = preprocessing(config, df, check_count=False, output_type=\"corrected_df\")\n",
    "for location in locations:\n",
    "    df.loc[df.location == location, \"population\"] = int(population_df.loc[population_df.Location == location, \"2011\"].values[0])\n",
    "    df.loc[df.location == location, locations] = neighbourhood_df.loc[neighbourhood_df.index==location,locations].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78474246-f389-46ee-be47-4de094bd61e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating the different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd2a5fd-19ff-4781-9d77-d171295cffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split with no additional features and training start in 2010\n",
    "#data_splits_dict[\"without_features_2001\"] = list(train_test_split(config, df, False))\n",
    "data_splits_dict[\"2001\"] = list(train_test_split(config, df, True))\n",
    "\n",
    "# Change the beginning of the training period\n",
    "config.train_start_time = datetime(2010,1,1,0,0,0)\n",
    "#data_splits_dict[\"without_features_2010\"] = list(train_test_split(config, df, False))\n",
    "data_splits_dict[\"2010\"] = list(train_test_split(config, df, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81ddd0-a9e9-43c4-a2b5-da51d4e8db2b",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d5812-3a28-4d3f-8c0c-e3fab2cb50b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.85it/s, epoch=1/8, avg_epoch_loss=1.05]\n",
      "100%|██████████| 50/50 [00:03<00:00, 12.80it/s, epoch=2/8, avg_epoch_loss=1.99]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.58it/s, epoch=3/8, avg_epoch_loss=0.982]\n",
      "100%|██████████| 50/50 [00:03<00:00, 12.88it/s, epoch=4/8, avg_epoch_loss=0.726]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.20it/s, epoch=5/8, avg_epoch_loss=2.25]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.22it/s, epoch=6/8, avg_epoch_loss=1.04]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.49it/s, epoch=7/8, avg_epoch_loss=0.582]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.30it/s, epoch=8/8, avg_epoch_loss=1.82]\n"
     ]
    }
   ],
   "source": [
    "deepAR_with_features = config.deeparestimator\n",
    "new_parameters = {\"use_feat_dynamic_real\" : False,\n",
    "                  \"use_feat_static_real\" : False}\n",
    "deepAR_without_features = update_deepAR_parameters(config, new_parameters)\n",
    "\n",
    "\n",
    "model_dict = {\"DeepAR_without_features\":deepAR_without_features, \"FFNN\":config.feedforwardestimator, \"DeepAR_with_features\":deepAR_with_features}\n",
    "for data_split in data_splits_dict.keys():\n",
    "    print(data_split)\n",
    "    forecasts_dict, evaluator_df_dict = forecast_by_week(config, data_splits_dict[data_split][0], data_splits_dict[data_split][1], locations, model_dict)\n",
    "    output_dict[data_split] = [forecasts_dict, evaluator_df_dict]\n",
    "    #plot_coverage(config, evaluator_df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd42381-7b8f-45d8-85fe-b528f1cfefce",
   "metadata": {},
   "source": [
    "# Comparative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010c855-26c8-4a91-acc5-91b473c0a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_evaluation_df = pd.DataFrame()\n",
    "for data_split in output_dict.keys():\n",
    "    forecasts_dict = output_dict[data_split][0]\n",
    "    evaluator_df_dict = output_dict[data_split][1]\n",
    "    #print(data_split)\n",
    "    #plot_coverage(config, evaluator_df_dict)\n",
    "    for key in evaluator_df_dict.keys():\n",
    "        evaluation_df = evaluator_df_dict[key].copy()\n",
    "        evaluation_df = evaluation_df.loc[evaluation_df.item_id.isin([item_id for item_id in evaluation_df.item_id if \"aggregate\" in item_id]),]        \n",
    "        evaluation_df['ID'] = str(data_split) + str(key)\n",
    "        final_evaluation_df = pd.concat([final_evaluation_df, evaluation_df])\n",
    "for i in range(1,5):\n",
    "    print(f\"Week-{i}-Ahead\")\n",
    "    print(final_evaluation_df.loc[final_evaluation_df.item_id == \"aggregated {\"f\"{i}\"+\"}\" ,[\"ID\", \"mean_WIS\", \"MAE_Coverage\"]].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe849b-a296-41d0-83ab-65a44277300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 9), sharey=True)\n",
    "for i in range(1,5):\n",
    "    if i == 1:\n",
    "        plotnumber = (0, 0)\n",
    "    if i == 2:\n",
    "        plotnumber = (0, 1)\n",
    "    if i == 3:\n",
    "        plotnumber = (1, 0)\n",
    "    if i == 4:\n",
    "        plotnumber = (1, 1)\n",
    "    axs[plotnumber].bar(final_evaluation_df.loc[final_evaluation_df.item_id == \"aggregated {\"f\"{i}\"+\"}\",\"ID\"], final_evaluation_df.loc[final_evaluation_df.item_id == \"aggregated {\"f\"{i}\"+\"}\",\"mean_WIS\"])\n",
    "    axs[plotnumber].set_title(f\"mean_WIS Scores Week-{i}-ahead\")\n",
    "fig.autofmt_xdate(rotation=60, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEST_PYTHON_KERNEL",
   "language": "python",
   "name": "test_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
